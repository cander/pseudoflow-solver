\section{Phase-based Solver}
The solver manages the entire problem instance.  Initially
this includes the nodes and edges.  These are stored as contiguous
arrays (as opposed to allocating each one individually with [[new]])
to make memory management fast and simple.  These arrays are allocated
when the problem instance is read.
<<Solver data>>=
    Node*	nodes;
    Edge*	edges;
@ %def nodes edges
<<default Solver constructor>>=
    nodes = nil;
    edges = nil;
@ 
Just for safety checking, we should also keep track of the
number of elements in each of these arrays.
<<Solver data>>=
    int		numNodes;
    int		numEdges;
<<default Solver constructor>>=
    numNodes = numEdges = 0;
@ %def numNodes numEdges
We also need to know the source and sink nodes in the graph.
<<Solver data>>=
    NodePtr 	sourceNode;
    NodePtr 	sinkNode;
<<default Solver constructor>>=
    sourceNode = sinkNode = nil;
@ %def sourceNode sinkNode
\subsection{Solving}
At the highest level, solving is pretty simple: we select the
lowest labeled strong branch, process it looking for mergers and 
relabling nodes that do not merge, and continue until we cannot
find a strong branch.  We can select different policies for managing the list of strong
branches (the buckets).  

The solver function below performs the usual, full normalization 
after each merger: push the flow all the way from the strong root
to the weak root.  Later we will introduce another solver that
only performs a partial normalization after each merger.
<<Solver methods>>=
    void solve(AddBranchPtr addFunc);
<<Solver method implementations>>=
void PhaseSolver::solve(AddBranchPtr addFunc)
{
    TRACE(int currentPhase = 0;)
    addBranchFunc = addFunc;
    renormalizeFunc = &PhaseSolver::fullRenormalize;

    NodePtr strongBranch = getLowestBranch();
    while (strongBranch != nil) {
	NodeLabel strongLabel =  strongBranch->getLabel();
	TRACE(
	    if ( strongLabel != currentPhase) {
		currentPhase = strongLabel;
		trout << "Phase " << currentPhase << endl;
	    }
	)
	<<terminate early based on counting labels>>
	processBranch(*strongBranch);
	strongBranch = getLowestBranch();
    }
}
@ %def solve
For each possible value for a node's label, if we track the number of 
nodes with that label, then it is possible to terminate the algorithm
early.  If the lowest labeled strong branch has label $\ell$, and
there are no nodes with label $\ell - 1$, then the algorithm is done
because the strong branch cannot merge with any weak branches, and
the labels of the strong branches will only increase further during
execution.
<<terminate early based on counting labels>>=
    #ifdef TERM_LABELS
	if ((labelCount[strongLabel - 1] == 0) && 
	    (strongLabel > INIT_WEAK_LABEL))
	{
	    cout << "Early termination" << endl;
	    break;
	}
    #endif /* TERM_LABELS */
@
\subsection{Delayed Normalization}
An alternative solving method involves `delayed normalization'.
In this case, we process the branches as before, but during a
merger, the tree is not totally renormalized.  In particular,
we do not push excess up the weak branch.  This leaves some
`pseudo-weak' branches, branches that we treat as weak, but they
have excess in them that may, in fact, make them strong.  
At the end of a phase, we need to scan for
weak nodes with excess and complete normalization on them.  This
may lead to the creation of more strong branches, in which case
we need to continue executing the algorithm.
<<Solver methods>>=
    void delayedNormalizeSolve(AddBranchPtr addFunc);
<<Solver method implementations>>=
void PhaseSolver::delayedNormalizeSolve(AddBranchPtr addFunc)
{
    addBranchFunc = addFunc;
    renormalizeFunc = &PhaseSolver::strongOnlyRenormalize;

    int currentPhase = 0;
    NodePtr strongBranch = nil; 
    NodeLabel strongLabel =  0;

    while (TRUE) {
	<<get strong branch - normalize if needed>>

	if ((labelCount[strongLabel - 1] == 0) && 
	    (strongLabel > INIT_WEAK_LABEL))
	{
	    cout << "Breaking at phase " << strongLabel << endl;
	    break;
	}

	processBranch(*strongBranch);
    }
}
@ %def delayedNormalizeSolve
To get the next strong branch, we call [[getLowestBranch]], but that
might return [[nil]] if the only remaining `strong' branches are
still weak due to deferred normalization.  In that case, we perform
the deferred normalizations and get the lowest branch again.
<<get strong branch - normalize if needed>>=
    strongBranch = getLowestBranch(); 
    if (strongBranch == nil) {
	performDeferredNormalizations();
	<<get non-null branch>>
    }
@ 
If we get [[nil]] again, we really are done and should break out
of the loop.
<<get non-null branch>>=
	strongBranch = getLowestBranch();
	if (strongBranch == nil) {
	    break;
	}
@
Once we have the branch, we look to see if its label is different
than the current phase - i.e. are we trying to go to a new (higher)
phase.  If so, we put the branch back and do the renomalizations,
which might lead to a lower phase, which is why we put it back.
<<get strong branch - normalize if needed>>=
    strongLabel =  strongBranch->getLabel();
    if (strongLabel != currentPhase) {
	addStrongBranch(*strongBranch);	// should addHead
	performDeferredNormalizations();
@
Now, we try again to get a new branch.  If the label is 
different than the current phase, then we really are starting
a new phase.
<<get strong branch - normalize if needed>>=
	<<get non-null branch>>
	strongLabel =  strongBranch->getLabel();
	if (strongLabel != currentPhase) {
	    currentPhase = strongLabel;
	    TRACE( trout << "Phase " << currentPhase << endl;)
	}
    }
@ 
To perform the delayed normalizations, we run down the list
of deferred nodes.  For each node, we perform a complete weak push
up to the weak root.  Note that it is possible for multiple nodes
in a branch to be weak (actually, we're hoping for that).  This means
that a deferred push could make a branch strong, and later we'll be
doing another push to the same branch - i.e. a `weak' push within a
strong branch.  

This is fine, but it does mean that we cannot use
the same `next' pointer to build the list of deferred weak nodes
as we use for building the list of strong nodes.  A deferred weak node
(still in the list of weak nodes) could be made into a strong branch
root due to a push from a descendent node, which means it needs to be
in the strong list.
<<Solver methods>>=
    Boolean performDeferredNormalizations();
<<Solver method implementations>>=
Boolean PhaseSolver::performDeferredNormalizations()
{
    int numWeakPushes = 0;
    int numSplittingPushes = 0;

    NodePtr currNode = deferredNodes;
    while (currNode != nil) {
	deferredNodes = currNode->next2;
	currNode->next2 = nil;

	if (currNode->flag != 0) {
	    if (currNode->getExcess() > 0) {
		numWeakPushes++;
		TRACE( trout << "deferred push from node " << currNode->getId() 
		             << " label " << currNode->getLabel() << endl;)
		if (weakPush(*currNode)) {
		    numSplittingPushes++;
		}
	    } else {
		TRACE( trout << "no deferred push from node " << currNode->getId() << endl; )
	    }
	    currNode->flag = 0;
	} 
	currNode = deferredNodes;
    }

    deferredNodes = nil;

    TRACE( trout << "Performed " << numWeakPushes << " pushes with " 
		 << numSplittingPushes << " splitting pushes"  << endl; )

    return (numSplittingPushes > 0) ? TRUE : FALSE;
}
@ %def performDeferredNormalizations
There is another strategy for performing deferred normalizations that
we have not yet implemented.  The basic idea is to try to push in parallel
from the leaves up to the root.  What we'd like to acheive is that
the excess from two parallel paths would merge at one node and we'd
then only have to do one push from that node up to the root.

We cannot really implement that directly.  We can approximate it by 
maintaining another set of buckets indexed by node label.  We process
it from maximum label down to zero.  We push excess from a node
up along the path to the root so long as the parent has the same
label.  As soon as we push flow up to a new labeled node, we queue
that node to be processed later when we get to that label.  This 
scheme might not detect the merger of two paths immediately, but it
would be detected as soon as we crossed into a new label.

This scheme might be an improvement due to coalescing the excess
from multiple paths into a single push up to the root.  On the
other hand, it involves a fair amount of overhead to be queueing
and dequeueing the nodes all the time.  Not to mention, it's more
compilicated, of course.

\subsection{Processing Branches}
We process the tree one branch at a time looking for mergers or
relabeling nodes.  As soon as there is a merger, we stop processing
this branch to allow the main loop to fetch the next, lowest-labeled
branch from the buckets.  It could be that we resume processing this 
branch, which is OK.  In fact, it is probably desireable since
the branch has been inverted.  If there was no merger, we
move the branch to the next bucket.

As an optimization, we check to see if there are any nodes that
we could possibly merge with before invesigating the branch.
If there are no nodes with a label one less than ours, we just
relabel the whole branch.  This shouldn't happen very often
any more, especially since we count the nodes with each label value
and terminate early.  It might still be invoked as a side-effect of
some initialization or normalization schemes - especially if we
queue a branch with $\ell = 1$, the initial value for weak nodes.
<<Solver methods>>=
    void processBranch(Node& root);
<<Solver method implementations>>=
void PhaseSolver::processBranch(Node& root)
{
#ifdef COUNT_LABELS
    if (labelCount[root.getLabel() - 1] == 0) {
#else /* !COUNT_LABELS */
    if (FALSE) {
#endif /* COUNT_LABELS */
	TRACE( trout << "Relabel branch " << root.getId() 
	             << " with label " << root.getLabel() << endl; )
	relabelSubtree(root);
	addStrongBranch(root);	// XXX maybe this should be in solve

    } else {
	Boolean performedMerger = processSubtree(root);
	if (!performedMerger) {
	    addStrongBranch(root);	// XXX maybe this should be in solve
	}
    }
}
@ %def processBranch
Below is recursive code to perform the DFS scan of a node's children and to
look for merger arcs among its neighbors.  Currently, the code
processes the nodes in post-order - i.e. the children are all processed
before the neighbors of this node are scanned.
If this function performs a merger, it returns immediately.
If any part of the sub-tree is split off and strong, it will
be put in the appropriate bucket where [[getLowestBranch]] will
find it.  If there is no merger, the label of this node is incremented.
The function returns true or false if we perform a merger.
<<Solver methods>>=
    Boolean processSubtree(Node& node);
<<Solver method implementations>>=
Boolean PhaseSolver::processSubtree(Node& node)
{
    NodeLabel label = node.getLabel();
    <<process all children>>
    <<look for merger among neighbors>>
    // no merger
    incrementLabel(node);
    node.resetIterations();
    TRACE(trout << "node " << node.getId() << " relabled to "
		<< node.getLabel() << endl;);
    return FALSE;
}
@ %def processSubtree
We process all children that have the same label as ours, [[label]].
If a child has a higher label, we just ignore it.  By monotonicity,
it can't have a label less than ours.  If we process the sub-tree
and that generates a merger we return immediately.
<<process all children>>=
    while (node.hasMoreChildren()) {
	Node& child = node.getCurrentChild();
	assert(child.getLabel() >= label);
	if (child.getLabel() == label) {
	    Boolean performedMerger = processSubtree(child);
	    if (performedMerger) {
		return TRUE;
	    }
	}
	node.advanceChildren();
    }
@
Processing neighbors is a bit different.  Here is where we look for
a merger to a node with label exactly one less that ours
(given that the arc has residual capacity).  
If we find that, we will merge and return true immediately.

{\em Note: there is a slight problem below.  We check for 
a positive capacity on the arc (instead of non-negative), 
but if we ever implemented a scheme
where we didn't split immediately up zero residual capacity, we 
would have zero-capacity arcs that are in the tree (i.e. the parent
arc), but we wouldn't want to use them for mergers.  This would
be a mess, but we could overcome it.}
<<look for merger among neighbors>>=
    while (node.hasMoreNeighbors()) {
	Edge& neighborEdge = node.getCurrentNeighbor();
	Node& neighbor = *neighborEdge.getOtherNode(&node);
	if ((neighbor.getLabel() == (label - 1)) &&
	    (neighborEdge.residCapacity(node) > 0))
	{
	    merge(node, neighbor, neighborEdge);
	    return TRUE;
	}
	node.advanceNeighbors();
    }
@
This function 
rehangs the strong branch from the strong node, adds the
merger arc from $s$ to $w$, and renormalizes the tree by
pushing the excess from the old strong root towards the weak root.  
There are different possible policies for renormalizing the tree
after a merger, so we use a pointer to function as an indirection.
<<Solver methods>>=
    void merge(Node& strong, Node& weak, Edge& edge);
<<Solver method implementations>>=
void PhaseSolver::merge(Node& strong, Node& weak, Edge& edge)
{
    TRACE( trout << "merge " << strong.getId() << " ("
		   << strong.getRootExcess() << ") to " 
		   << weak.getId() << " ("
		   << weak.getExcess() << ", "
		   << weak.getRootExcess() << "), cap "
		   << edge.residCapacity(strong) << ", s-label "
		   << strong.getLabel() << endl;)
    Node& strongRoot = *strong.rehang();
    weak.addChild(strong, edge);
    CHECK_TREE(weak, weak.getParentEdge());
    CHECK_TREE(*weak.getRoot(), nil);

    // renormalize the tree
    (this->*renormalizeFunc)(strongRoot, weak);
}
@ %def merge
<<Solver data>>=
    RenormalizePtr renormalizeFunc;
<<default Solver constructor>>=
    renormalizeFunc = &PhaseSolver::fullRenormalize;
@
Push excess from the former strong root, [[src]] to the strong node 
and one step beyond to the weak node, [[dest]].
When this finishes, the remaining excess will be stored on
the destination node.
We save the parent pointer before the push in case there is a
split, in which case the parent pointer will be [[nil]].
<<Solver methods>>=
    void strongPush(Node& src, Node& dest);
<<Solver method implementations>>=
void PhaseSolver::strongPush(Node& src, Node& dest)
{
    NodePtr currNode = &src;
    while (currNode != &dest) {
	NodePtr parent = currNode->getParentNode();
	Boolean performedSplit = currNode->pushToParent();
	<<check for zero-capcity split>>

	if (performedSplit) {
	    if (currNode->getExcess() > 0 ||
	        currNode->getExcess() == 0 && zeroDeficitIsStrong)
	    {	
		addStrongBranch(*currNode);
	    } 
	}
	currNode = parent;
    }
}
@ %def strongPush
We allow special handling if an edge has zero residual capacity.
It could be split or left alone.
<<check for zero-capcity split>>=
    if (performedSplit == FALSE && 
	currNode->getParentCapacity() == 0 &&
	splitOnZeroCapacity) 
    {
	currNode->split();
	performedSplit = TRUE;
    }
@
We need to determine if a node is strong.  Usually, this means that
it has positive excess, but in some cases, we can choose to treat
a node with zero excess as strong.  We want to select that at
runtime for experimentation.
<<Solver methods>>=
    Boolean isStrongNode(const Node& node);
<<Solver inline implementations>>=
INLINE Boolean PhaseSolver::isStrongNode(const Node& node)
{
    FlowAmount excess =  node.getExcess();
    return ((excess > 0) || ((excess == 0) && zeroDeficitIsStrong)) ?
	    TRUE : FALSE;
}
@ %def isStrongNode
Pushing on the weak side is similar in that it uses [[pushToParent]]
to push all of the flow, but it differs in that we push all the way
to the root of the branch.
The function returns true if we perform any splits - i.e. create
any new strong branches.
<<Solver methods>>=
    Boolean weakPush(Node& src);
<<Solver method implementations>>=
Boolean PhaseSolver::weakPush(Node& src)
{
    Boolean result = FALSE;
    NodePtr currNode = &src;
    NodePtr parent = currNode->getParentNode();

    while (parent != nil) {
	Boolean performedSplit = currNode->pushToParent();
	currNode->flag = 0;
	<<check for zero-capcity split>>

	if (performedSplit) {
	    CHECK_TREE(*currNode, nil);
	    if (currNode->getExcess() > 0 ||
	        currNode->getExcess() == 0 && zeroDeficitIsStrong)
	    {	
		// should worry about l=1
		addStrongBranch(*currNode);
		result = TRUE;
	    } 
	}
	currNode = parent;
	parent = currNode->getParentNode();
    }

    CHECK_TREE(*currNode, nil);
    currNode->flag = 0;

    <<check for weak root becoming strong>>
    return result;
}
@ %def weakPush
After we have pushed flow all the way to the weak root, we need to
check to see if the weak root is now strong.  The weak root is
pointed to by [[currNode]].  One special case we deal with here
is if the weak root has the initial weak label, we know that when 
it goes strong, there will be no one 
for it to merge with (because the weak label is the lowest possible).
Therefore, we can just relabel it here and now before adding it.
<<check for weak root becoming strong>>=
    if (currNode->getExcess() > 0 ||
	currNode->getExcess() == 0 && zeroDeficitIsStrong)
    {
	//if (currNode->getLabel() == INIT_WEAK_LABEL) {
	    //relabelSubtree(*currNode);
	//}
	addStrongBranch(*currNode);
	result = TRUE;
    }
@
In the code above, we used some flags to control some of the
behavior of the code while it's running.  We'll declare these
public so that they can be easily inspected and tweaked.
The first flag controls what happens if we push excess along an
arc that matches the residual capacity.  We could choose to
either split it or leave it alone until the next push sends
flow along the arc, which will cause an immediate split.
<<public Solver data>>=
    Boolean splitOnZeroCapacity;
@
The second flag controls how we regard zero-deficit nodes/branches during
the execution of the algorithm (they are always weak when start the
algorithm).  If we treat a zero-deficit node as weak, when the algorithm
finishes, the strong nodes will be a minimal source set.  However, this
can lead to creating weak branch with root nodes whose label is greater
than one.  This in turn makes it very difficult (impossible?) to bound 
the maximum label that weak node can take (if weak roots have label one,
no node can have a label greater than $n$).  If we treat zero-deficit
nodes as strong, weak roots will always have label one, we will never
create any additional zero-deficit nodes/branches, but we have no easy
way to find a minimal source set.
<<public Solver data>>=
    Boolean zeroDeficitIsStrong;
<<default Solver constructor>>=
    splitOnZeroCapacity = FALSE;
    zeroDeficitIsStrong = FALSE;
@ %def splitOnZeroCapacity zeroDeficitIsStrong
After we have attached the strong branch to the weak node, we need
to renormalize the tree to push excess from the old strong root
up to the weak node and onto the weak root.  This is the default,
full normalization procedure.
<<Solver methods>>=
    void fullRenormalize(Node& strongRoot, Node& weakNode);
<<Solver method implementations>>=
void PhaseSolver::fullRenormalize(Node& strongRoot, Node& weakNode)
{
    strongPush(strongRoot, weakNode);
    weakPush(weakNode);
}
@ %def fullRenormalize
As an alternative, we can choose to only renormalize the strong
branch.  This will leave excess at the weak node.  The weak branch
will still be considered weak so that strong nodes can still merge
to it.  
However, if the weak node is a root, and it ends up with
positive excess, we need to add it as a strong branch immediately.
Otherwise, it's impossible for us to recognize it later as a weak
branch that should be strong.
<<Solver methods>>=
    void strongOnlyRenormalize(Node& strongRoot, Node& weakNode);
<<Solver method implementations>>=
void PhaseSolver::strongOnlyRenormalize(Node& strongRoot, Node& weakNode)
{
    strongPush(strongRoot, weakNode);
    if (weakNode.flag == 0) {
	weakNode.flag = 1;
	weakNode.next2 = deferredNodes;
	deferredNodes = &weakNode;
    }
}
@ %def strongOnlyRenormalize
<<Solver data>>=
    NodePtr deferredNodes;
<<default Solver constructor>>=
    deferredNodes = nil;
@ %def deferredNodes
Back in [[processSubtree]] we had a simple method call to increment
the label on a node.  Normally, we would just call [[incrementLabel]]
on the node, but we want to track how many nodes we have with each
label so that we can terminate the algorithm early.
<<Solver methods>>=
    void incrementLabel(Node& node);
@
When the label of a node is incremented, we decrement the old label
count by one and increment the new label count.
<<Solver inline implementations>>=
INLINE void PhaseSolver::incrementLabel(Node& node)
{
#ifdef  COUNT_LABELS 
    NodeLabel l = node.getLabel();
    labelCount[l]--;
    labelCount[l + 1]++;
#endif /* COUNT_LABELS */
    node.incrementLabel();
}
@ %def incrementLabel
When we know that a branch cannot merge with
any weak nodes, we need to increment the label
of the branch, and all of its children that have the same label.
This is really a stripped down version of [[processSubtree]].
Given the early termination code based on counting nodes and labels,
this code isn't usually needed.  It might be useful for some
tree initialization schemes that result in strong branches with
the initial weak label.
<<Solver methods>>=
    void relabelSubtree(Node& node);
<<Solver method implementations>>=
void PhaseSolver::relabelSubtree(Node& node)
{
    NodeLabel label = node.getLabel();
    node.resetIterations();
    while (node.hasMoreChildren()) {
	Node& child = node.getCurrentChild();
	assert(child.getLabel() >= label);
	if (child.getLabel() == label) {
	    relabelSubtree(child);
	}
	node.advanceChildren();
    }

    incrementLabel(node);
    node.resetIterations();
    TRACE(trout << "node " << node.getId() << " Relabled to "
		<< node.getLabel() << endl;);
}
@ %def relabelSubtree
To clean up the management of the buckets, let's introduce a 
simple class.

{\em Note: using a bucket class instead of separate head and
tail pointers seemed to case a performance hit of about
1.7\% - cher.20.20 w/o buckets = 35.7, with buckets =36.3 seconds. }
<<Node Bucket data>>=
private:
    NodePtr	head;
    NodePtr	tail;
<<Node Bucket methods>>=
public:
    void 	insertHead(Node& root);
    void	insertTail(Node& root);
    NodePtr	removeHead();
@
We will always implement these as inline functions:
<<Node Bucket inline implementations>>=
inline void 
NodeBucket::insertHead(Node& root)
{
    if (head == nil) {
	root.setNextNil();
	head = &root;
#ifdef LIFO_BUCKETS
	tail = &root;
#endif /* LIFO_BUCKETS */
    } else {
	root.setNext(head);
	head = &root;
    }
}
#ifdef LIFO_BUCKETS
inline void 
NodeBucket::insertTail(Node& root)
{
    if (head == nil) {
	root.setNextNil();
	head = &root;
	tail = &root;
    } else {
	tail->setNext(&root);
	tail = &root;
	root.setNextNil();
    }
}
#endif /* LIFO_BUCKETS */
inline NodePtr
NodeBucket::removeHead()
{
    NodePtr result = nil;
    if (head != nil) {
	result = head;
	head = result->getNext();
#ifdef LIFO_BUCKETS
	if (head == nil) {
	    tail = nil;
	}
#endif /* LIFO_BUCKETS */
    }

    return result;
}
@ %def insertHead insertTail removeHead
Here are a couple of obvious accessor functions.
<<Node Bucket methods>>=
    NodePtr getHead() const { return head; }
    NodePtr getTail() const { return tail; }
<<Solver data>>=
    NodeBucket*	buckets;
<<default Solver constructor>>=
    buckets = nil;
@ %def buckets
<<Node Bucket methods>>=
    void	dumpBucket();
@ 
\{em Note: this is in the `wrong' chunck Solver rather than bucket.}
<<Solver method implementations>>=
void 
NodeBucket::dumpBucket()
{
    cout << "head = " << head;
    if (head != nil) {
	cout << " (" << head->getId() << "), tail = " 
	     << tail << " (" << tail->getId() << ")" << endl;
    } else {
	cout << ", tail = " << tail << endl;
	return;
    }
    for (NodePtr n = head; n != nil; n = n->getNext()) {
	cout << n->getId() << "  ";
    }
    cout << endl;
}
@
Because we process the lowest labeled branch, we need a way to find
the strong branch quickly.  At the moment, we just search the list
sequentially looking for the lowest labeled, non-empty bucket.  To
speed this a bit, we keep track of the lowest labeled bucket we've
seen.  In the future, this simple array of buckets could be replaced
by some sort of heap.
<<Solver data>>=
    NodeLabel 	lowestLabel;
<<default Solver constructor>>=
    lowestLabel = 0;
@ %def lowestLabel
Adding a branch just requires finding the bucket based on the branch's
label, and inserting it into the list.  
<<Solver methods>>=
    void addStrongBranch(Node& root);
<<Solver inline implementations>>=
INLINE void PhaseSolver::addStrongBranch(Node& root)
{
    assert(zeroDeficitIsStrong ? (root.getExcess() >= 0) :
				 (root.getExcess() > 0));
    CHECK_TREE(root, nil);
    NodeLabel label = root.getLabel();

    <<check if root is already in the tree>>

    // actually add the branch
    (this->*addBranchFunc)(root);

    // look for new lowest label
    if (label < lowestLabel) {
	lowestLabel = label;
    }
}
@ %def addStrongBranch
This is a little tricky because we don't have a flag that to tell
us directly if the node is already in the tree.  Instead, we will
just look at the next pointer.  If the pointer is non-null, then
it must already be in a bucket.  However, the pointer might be
null if it's the last node in the bucket, so we have to check for
that too.  If it is in the bucket, we'll check its label against
the label of the nodes already in the tree.
<<check if root is already in the tree>>=
    if ((root.getNext() != nil) || 
        (buckets[label].getTail() == &root))
    {
	assert(buckets[label].getHead()->getLabel() == root.getLabel());
	return;
    }

<<Solver data>>=
    AddBranchPtr addBranchFunc;
<<default Solver constructor>>=
    addBranchFunc = &PhaseSolver::addBranchLifo;
@ %def addBranchFunc
<<Solver methods>>=
    void addBranchFifo(Node& root);
    void addBranchLifo(Node& root);
    void addBranchWave(Node& root);

<<Solver method implementations>>=
void PhaseSolver::addBranchFifo(Node& root)
{
    buckets[root.getLabel()].insertHead(root);
}
void PhaseSolver::addBranchLifo(Node& root)
{
    buckets[root.getLabel()].insertTail(root);
}
void PhaseSolver::addBranchWave(Node& root)
{
    if (lastRoot == &root) {
	buckets[root.getLabel()].insertHead(root);
    } else {
	buckets[root.getLabel()].insertTail(root);
    }
}
<<Solver data>>=
    NodePtr lastRoot;
<<default Solver constructor>>=
    lastRoot = nil;
@ 
As the algorithm runs, we need to remove the lowest labeled branch.
First we need to locate the lowest labeled bucket, then we need to
remove the head of the list.  If there are no more strong branches,
we just return [[nil]].

The search always starts at the [[lowestLabel]] bucket.  As we
scan buckets, we increment [[lowestLabel]] until we find a 
non-empty bucket.
{\em What exactly should the termination condition be?}
<<Solver methods>>=
    NodePtr getLowestBranch();
<<Solver method implementations>>=
NodePtr PhaseSolver::getLowestBranch()
{
    NodePtr result = nil;
    while (lowestLabel < numNodes) {
	result = buckets[lowestLabel].removeHead();
	if (result != nil) {
	    assert(result->getLabel() == lowestLabel);
	    result->setNextNil();
	    break;
	} else {
	    lowestLabel++;
	}
    }

    lastRoot = result;
    return result;
}
@ %def getLowestBranch
\subsection{Establishing an Initial Normalized Tree}
There are a number of different ways that we can build an initial,
normalized tree.  Building the initial tree is totally independent
of the execution of the algorithm.  

\subsubsection{Simple Initialization}
At the very least, this simplest initialization
needs to saturate all source- and sink.adjacent edges and
source-adjacent nodes 2, and label the others 1.
classify the nodes as strong or weak.
<<Solver methods>>=
    void buildSimpleTree();
<<Solver method implementations>>=
void PhaseSolver::buildSimpleTree()
{
    saturateSourceSinkArcs();
    setInitialNodeStatus();
}
@ %def buildSimpleTree
The code to saturate the source- and sink-adjacent arcs is
broken out into a separate function because many schemes
for building the initial tree will want start by saturating
these arcs.  When we saturate an edge, we remove it from the list
of arcs for the node.  This will prevent flow from going back to
either the source or the sink without having to special-case these
arcs at run-time.
<<Solver methods>>=
    void saturateSourceSinkArcs();
<<Solver method implementations>>=
void PhaseSolver::saturateSourceSinkArcs()
{
    for (int i = 0 ; i < numEdges; i++) {
	Edge& edge = edges[i];
	if (edge.getTail() == sourceNode) {
	    FlowAmount excess = edge.saturate();
	    Node& srcAdjNode = *edge.getHead();
	    srcAdjNode.removeNeighbor(edge);
	    srcAdjNode.incrementExcess(excess);
	} else if (edge.getHead() == sinkNode) {
	    FlowAmount excess = edge.saturate();
	    Node& sinkAdjNode = *edge.getTail();
	    sinkAdjNode.decrementExcess(excess);
	    sinkAdjNode.removeNeighbor(edge);
	}
    }
}
@ %def saturateSourceSinkArcs
Again, since determining the initial status of nodes is apt
to be a common subroutine of many initialization procedures,
we have it as a separate method.  We simply iterate over
all of the nodes setting their initial labels based on their
excess.  Anything with positive excess is assumed to be
strong, and everything else is assumed to be weak.
Strong nodes are added as strong branches.

{\em Note:} this code assumes that each node is it's own
branch - i.e. no trees or paths have been built up.  
If we have built any branches, then the non-root nodes will
have zero excess, but we cannot immediately discern their
status based simply on their excess.  In order to make this
method useful to schemes that may build up branches, we
check the label of the branch.  If it is still at the initial value
from when the node was created, we assume it is safe for us to
label it.
<<Solver methods>>=
    void setInitialNodeStatus();
<<Solver method implementations>>=
void PhaseSolver::setInitialNodeStatus()
{
    for (int i = 1; i <= numNodes; i++) {
	Node& node = nodes[i];
	if (node.getLabel() == Node::INITIAL_LABEL) {
	    if (node.getExcess() > 0) {	// ZERO DEFICIT
		node.setLabel(INIT_STRONG_LABEL);
		labelCount[INIT_STRONG_LABEL]++;
		addStrongBranch(node);
	    } else {
		node.setLabel(INIT_WEAK_LABEL);
		labelCount[INIT_WEAK_LABEL]++;
	    }
	}
    }
}
@ %def setInitialNodeStatus
<<Solver data>>=
    int* labelCount;
<<default Solver constructor>>=
    labelCount = nil;
@ %def labelCount 
<<Solver data>>=
    static const int INIT_STRONG_LABEL=2;
    static const int INIT_WEAK_LABEL=1;
    static const int INIT_ZERO_LABEL=1;
@ %def INIT_STRONG_LABEL INIT_WEAK_LABEL INIT_ZERO_LABEL
\subsubsection{Blocking Path Initialization}
A simple extension to the idea of just simply saturating the
source- and sink-adjacent arcs is to try to push flow from the
source-adjacent nodes into the interior of the graph.  Our
objective is to try to build some simple but large components
with a minimum of work.

This is a bit more involved than it initially appeared.
The first thing to note is that the components we will build will
be paths.  This means that we can only push flow out of a node
along a single outgoing arc.  Also, we can only push flow into
a node from a single neighbor.  Otherwise, we might end up building
components that are not trees.

Because we wish to build components that are as large as possible
(rather than creating lots of small components), we want to avoid
splitting edges.  However, this can be problematic because many of
the random graphs we test with have more in-capacity than out-capacity
for the source-adjacent nodes.  If we blindly avoid splitting, we
won't move any flow from the source-adjacent nodes because they
have more excess than out-capacity.  

One final complication is that if we sucessfully push flow into a
node and then out of it, then its excess will be zero, but the node
should be regarded as strong because it belongs to a strong branch
(path).

With all of this in mind, we proceed by finding nodes with 
positive excess that still have their initial label.
We then push the flow out of the node and expect that every node
we visit while pushing flow will be relabeled.  Basically, we
are using the node's label as a marker indicating that we have
visited the node.
<<Solver methods>>=
    void buildBlockingPathTree();
<<Solver method implementations>>=
void PhaseSolver::buildBlockingPathTree()
{
    saturateSourceSinkArcs();

    for (int i = 1; i <= numNodes; i++) {
	Node& node = nodes[i];
	if ((node.getExcess() > 0) && 
	    (node.getLabel() == Node::INITIAL_LABEL))
	{	
	    blockingPathPush(node);
	}
    }

    setInitialNodeStatus();
}
@ %def bulidBlockingPathTree
The real work in this greedy scheme is pushing the flow out of a
node.  This recursive function finds the `best' edge to push the
flow out on, and then we push the flow.  When we push flow out,
we make this node a child of the node at the other end of the arc,
and then we try to push flow out of that node (hence the recursion).
As we visit each node, we relabel it to prevent visiting the same node
more than once.

The function returns true if we eventually push the excess to
a sink-adjacent node with negative execess that exceeds the 
amount we are pushing.  In this case, we have created a weak
branch.  If we reach a point where the flow cannot be pushed
out of a node, that node then becomes the root of a strong branch,
and the function returns false.
<<Solver methods>>=
    Boolean blockingPathPush(Node& node);
<<Solver method implementations>>=
Boolean PhaseSolver::blockingPathPush(Node& node)
{
    Boolean foundSink = FALSE;
    node.setLabel(INIT_STRONG_LABEL);
    labelCount[INIT_STRONG_LABEL]++;

    NodeExcess excess = node.getExcess();
    Edge* bestOutEdge = nil;
    <<find best out-edge without split>>

    FlowAmount flow = excess;
    if (bestOutEdge != nil) {
	Node& otherNode = *bestOutEdge->getOtherNode(&node);
	TRACE( trout << "push positive excess (" << flow << " from " 
		     << node.getId() << " to " << otherNode.getId() << endl);
	         
	bestOutEdge->increaseFlow(flow);
	node.decrementExcess(flow);
	otherNode.incrementExcess(flow);
	otherNode.addChild(node, *bestOutEdge);

	<<recursively push flow out>>
    } else {
	TRACE( trout << "can't push excess from " << node.getId() << endl; )
	addStrongBranch(node);
    }

    return foundSink;
}
@ %def blockingPathPush
To find the best out edge, we iterate over all of the edges looking
for one that has at least enough capacity to handle the excess.  Also,
the edge must refer to a node that we haven't visited yet, as indicated
by its label.  If we find multiple edges with sufficient capacity, we
take the one with the least capacity.  Alternatively, we could take
the first fit, but we do not expect that scanning every edge will be
too burdensome.
<<find best out-edge without split>>=
    node.resetIterations();
    while (node.hasMoreNeighbors()) {
	Edge& edge = node.getCurrentNeighbor();
	if (edge.getOtherNode(&node)->getLabel() == Node::INITIAL_LABEL)
	{
	    if (edge.residCapacity(node) >= excess) {
		if (bestOutEdge == nil) {
		    bestOutEdge = &edge;
		} else if (bestOutEdge->residCapacity(node) > edge.residCapacity(node)) {
		    bestOutEdge = &edge;
		}
	    }
	    // else, could also track max capacity edge to split here
	}
	node.advanceNeighbors();
    }
    node.resetIterations();
@
One would think that continuing to push flow out would be pretty simple:
just call [[blockingPathPush(otherNode)]].  However, it's not that easy.
If we get lucky, we have pushed flow all the way to a sink-adjacent
node.  If that node had a negative excess that exceeds the excess
we are pushing out of [[node]], then we have have created a weak
branch, but we have already labeled all of the nodes as strong.  As
a slightly cheezy hack, we will undo the labeling.  Another solution
would be a more sophisticated version of [[setInitialNodeStatus]] that
finds roots of branches and labels all children strong or weak depending
on the root.
<<recursively push flow out>>=
    if (otherNode.getExcess() > 0) {	// ZERO_DEFICIT
	foundSink = blockingPathPush(otherNode);
    } else {
	TRACE( trout << "found sink-adjacent node " << otherNode.getId() << endl;)
	foundSink = TRUE;
	CHECK_TREE(otherNode, nil);
    }

    if (foundSink) {
	TRACE( trout << "relabeling "  << node.getId() << " as weak " << endl;)
	labelCount[INIT_STRONG_LABEL]--;
	node.setLabel(INIT_WEAK_LABEL);
	labelCount[INIT_WEAK_LABEL]++;
    }
@
\subsubsection{Splitting Path Initialization}
Greedy push with any number of splits allowed.
<<Solver methods>>=
    void buildGreedyPathTree();
<<Solver method implementations>>=
void PhaseSolver::buildGreedyPathTree()
{
    saturateSourceSinkArcs();

    for (int i = 1; i <= numNodes; i++) {
	Node& node = nodes[i];
	if ((node.getExcess() > 0) && 
	    (node.getLabel() == Node::INITIAL_LABEL))
	{	
	    splittingPathPush(node, 10);
	}
    }

    setInitialNodeStatus();
}
@ %def buildGreedyPathTree
<<Solver methods>>=
    Boolean splittingPathPush(Node& node, int remainingSplits);
<<Solver method implementations>>=
Boolean PhaseSolver::splittingPathPush(Node& node, int remainingSplits)
{
    Boolean foundSink = FALSE;
    /*
    node.setLabel(INIT_STRONG_LABEL);
    labelCount[INIT_STRONG_LABEL]++;

    NodeExcess excess = node.getExcess();
    Edge* bestOutEdge = nil;
    <<find best out-edge with split>>

    FlowAmount flow = excess;
    if (bestOutEdge != nil) {
	Node& otherNode = *bestOutEdge->getOtherNode(&node);
	TRACE( trout << "push positive excess (" << flow << " from " 
		     << node.getId() << " to " << otherNode.getId() << endl);
	         
	bestOutEdge->increaseFlow(flow);
	node.decrementExcess(flow);
	otherNode.incrementExcess(flow);
	otherNode.addChild(node, *bestOutEdge);

	<<recursively push flow out 2>>
    } else {
	TRACE( trout << "can't push excess from " << node.getId() << endl; )
	addStrongBranch(node);
    }
    */

    return foundSink;
}
@ %def blockingPathPush
<<find best out-edge with split>>=
    node.resetIterations();
    while (node.hasMoreNeighbors()) {
	Edge& edge = node.getCurrentNeighbor();
	if (edge.getOtherNode(&node)->getLabel() == Node::INITIAL_LABEL) {
	    if (edge.residCapacity(node) <= 0) {
		conintue;
	    }
	    if (bestOutEdge == nil) {
		bestOutEdge = &edge;
	    } 
	    if (edge.residCapacity(node) >= excess) {
		if (bestOutEdge->residCapacity(node) > 
		    edge.residCapacity(node)) 
		{
		    bestOutEdge = &edge;
		}
	    } else {
		if (edge.residCapacity(node) > 
		    bestOutEdge->residCapacity(node))
		{
		    bestOutEdge = &edge;
		}
	    }
	}
	node.advanceNeighbors();
    }
    node.resetIterations();

<<recursively push flow out 2>>=
    if (otherNode.getExcess() > 0) {	// ZERO_DEFICIT
	foundSink = blockingPathPush(otherNode);
    } else {
	TRACE( trout << "found sink-adjacent node " << otherNode.getId() << endl;)
	foundSink = TRUE;
	CHECK_TREE(otherNode, nil);
    }

    if (foundSink) {
	TRACE( trout << "relabeling "  << node.getId() << " as weak " << endl;)
	labelCount[INIT_STRONG_LABEL]--;
	node.setLabel(INIT_WEAK_LABEL);
	labelCount[INIT_WEAK_LABEL]++;
    }
@


\subsubsection{Staturate All Arcs}

<<Solver methods>>=
    void saturateAllArcs();
<<Solver method implementations>>=
void PhaseSolver::saturateAllArcs()
{
    for (int i = 0 ; i < numEdges; i++) {
	Edge& edge = edges[i];
	FlowAmount excess = edge.saturate();

	if (edge.getTail() == sourceNode) {
	    Node& srcAdjNode = *edge.getHead();
	    srcAdjNode.removeNeighbor(edge);
	    srcAdjNode.incrementExcess(excess);
	} else if (edge.getHead() == sinkNode) {
	    Node& sinkAdjNode = *edge.getTail();
	    sinkAdjNode.decrementExcess(excess);
	    sinkAdjNode.removeNeighbor(edge);
	} else {
	    edge.getTail()->decrementExcess(excess);
	    edge.getHead()->incrementExcess(excess);
	}
    }

    setInitialNodeStatus();
}
@ %def saturateAllArcs
\subsection{Input Output Functions}
We need routines to read Dimacs problem files and write 
Dimacs flow files.  At the moment, these are member
functions on the solver.  An alternative design would
be to put them in a separate class or file to allow us
to support multiple input file formats for the same 
solver class.

Our function to read a problem instance is given a file name and
return true if it sucessfully read the problem instance from the
specified file.
<<Solver methods>>=
    Boolean readDimacsInstance(const char* filename);
@
Our code will be divided into two steps. In the first
steps we will determine the basic dimensions of the problem, initialize
the edges, and compute the degree of each node.  Once we know the degree
of the nodes, we can initialize them and add all of their neighbors.

The code below uses C standard I/O ([[stdio]]) because I'm too lazy
to figure out how to use C++ I/O streams.  
<<Solver method implementations>>=
Boolean PhaseSolver::readDimacsInstance(const char* filename)
{
    FILE* fp = fopen(filename, "r");
    if (fp != NULL) {
	instanceFilename = filename;
	<<local variables for reading>>
	<<read instance and initialize edges>>
	<<initialize nodes>>
    } else {
	perror("Unable to read problem instance");
	return FALSE;
    }
    return TRUE;
}
<<implementation header files>>=
#include <stdio.h>
<<Solver data>>=
    const char* instanceFilename;
<<default Solver constructor>>=
    instanceFilename = "<unknown instance>";
@ %def readDimacsInstance
Reading the problem instance is farily straightforward.  We
read lines until the end of file.  Each line
in the file is identified by a `type character' that specifies what
type of line we are reading.  The type then determines how much more
information is on the line.  The additional information will begin 
at the third character in the line.
<<read instance and initialize edges>>=
    while (!feof(fp)) {
	char buffer[500];
	if (fgets(buffer, 500, fp) == NULL) {
	    break;
	}
	char* moreInfo = &buffer[2];
	char type;
	sscanf(buffer, "%c", &type);
	<<parse line>>
    }
@ 
Parsing the type code is a pretty simple switch statment.
<<parse line>>=
    switch (type) {
	case 'c':	// comment
	    break;
	case 'p':	// problem dimensions
	    <<allocate problem instance>>
	    break;
	case 'n':   {	// specify source or sink
	    <<specify source/sink>>
	    break;
	}
	case 'a':	// read an edge
	    <<read edge>>
	    break;
	default:
	    cerr << "Unrecognized input line: " << buffer << endl;
	    break;
    }
@
The problem instance has a problem type string, number of nodes,
and number of instances.  In addition to allocating the array
of nodes, we also allocate and zero an array of integers that we
will use to count the degree of each node as we read each edge.
Note that node id's begin at one rather than zero, so we need to
allocate an extra node (node zero), that never really gets used.
<<allocate problem instance>>=
    char typeBuffer[20];
    numTokens = sscanf(moreInfo, "%s %d %d", typeBuffer, &numNodes, &numEdges);
    if ((numTokens != 3) || (numNodes <= 0) || (numEdges <= 0)) {
	cerr << "Invalid problem instance line: " << buffer << endl;
	return FALSE;
    }
    nodes = new Node[numNodes + 1];
    edges = new Edge[numEdges];
    buckets = new NodeBucket[numNodes + 1];
    nodeDegrees = new int[numNodes + 1];
    labelCount = new int[numNodes + 1];

    for (int i = 0; i <= numNodes; i++) {
	nodeDegrees[i] = labelCount[i] = 0;
    }
<<local variables for reading>>=
    int numTokens = 0;
    int* nodeDegrees = nil;
@ 
The source and sink in the graph are simply specified by a node number and `s'
for the source and `t' for the sink.
<<specify source/sink>>=
    char sourceSinkFlag;
    int nodeNumber;
    numTokens =  sscanf(moreInfo, "%d %c", &nodeNumber, &sourceSinkFlag);
    if ((numTokens != 2) || (nodeNumber <= 0) || (nodeNumber > numNodes)) {
	cerr << "Invalid source/sink line: " << buffer << endl;
	return FALSE;
    }

    if (sourceSinkFlag == 's') {
	sourceNode = &nodes[nodeNumber];
    } else if (sourceSinkFlag == 't') {
	sinkNode = &nodes[nodeNumber];
    } else {
	cerr << "Invalid source/sink line: " << buffer << endl;
	return FALSE;
    }
@ 
An edge is specified by a source, destination and a capacity.
<<read edge>>=
    int source, dest, capacity;
    numTokens =  sscanf(moreInfo, "%d %d %d", &source, &dest, &capacity);
    if ((numTokens != 3) || (source <= 0) || (source > numNodes) ||
	(capacity < 0)   || (dest <= 0)   || (dest > numNodes)) {
	cerr << "Invalid edge line: " << buffer << endl;
	return FALSE;
    }

    if (nextEdge < numEdges) {
	edges[nextEdge].init(nodes[source], nodes[dest], capacity);
	nextEdge++;
	nodeDegrees[source]++;
	nodeDegrees[dest]++;
    } else {
	cerr << "Too many edges - graph should only contain " << numEdges << endl;
	return FALSE;
    }
<<local variables for reading>>=
    int nextEdge = 0;
@
To initialize the nodes, we call their [[init]] method to allocate
space for neighbors based on the degree of each node that we observered
while reading edges.  We can trivially assign each node it's id number.
<<initialize nodes>>=
    for (int i = 1; i <= numNodes; i++) {
	nodes[i].init(i, nodeDegrees[i]);
    }
@
Once the nodes are initialized, we can easily iterate over the list of 
edges and add each endpoint to the other's list of neighbors.  Note,
we only scan the edges that we actually read (based on [[nextEdge]])
rather than the number we could have seen (specified by [[numEdges]]).
<<initialize nodes>>=
    for (int i = 0; i < nextEdge; i++) {
	edges[i].getHead()->addNeighbor(edges[i]);
	edges[i].getTail()->addNeighbor(edges[i]);
    }
@
Finally, let's remember to free up the memory we allocated to count
node degrees.
<<initialize nodes>>=
    delete[] nodeDegrees;
@
After we read an instance and solve it, we need to write the result
out.  The Dimacs flow file is very similar to the instance in
that every line is identified by an initial type character followed
by arguments.  After printing header information, we print the
total flow amount and the flow on each arc.
<<Solver methods>>=
    void writeDimacsFlow(ostream& dout);
<<Solver method implementations>>=
void PhaseSolver::writeDimacsFlow(ostream& dout)
{
    <<write header>>
    dout << "s " << 0 << endl;
    <<dump arcs>>
}
@ %def writeDimacsFlow
<<write header>>=
    // dout << "c  instance: " << instanceFilename << endl;
    dout << "c  numNodes: " << numNodes << endl;
    dout << "c  numArcs: "  << numEdges << endl;
    dout << "c" << endl;
@
To dump the edges, we just iterate over the array of edges and 
print them out.
<<dump arcs>>=
    for (int i = 0; i < numEdges; i++) {
	edges[i].writeFlow(dout) << endl;
    }
@
Here is a new method to print the final disposition of all of the nodes
in the graph.  
<<Solver methods>>=
    void dumpNodes(ostream& out);
<<header include files>>=
    class ostream;
<<Solver method implementations>>=
void PhaseSolver::dumpNodes(ostream& out)
{
    out << "c" << endl
        << "c Node  id   excess  parent   label  strong/weak" << endl;

    for (int i = 1; i <= numNodes; i++) {
	Node& node = nodes[i];
	out << "c " << setw(8) << node.getId() << " " << setw(8);
	if (&node == sourceNode) {
	    out << "source";
	} else if (&node == sinkNode) {
	    out << "sink";
	} else {
	     out << node.getExcess() << setw(8);
	     if (node.isRootNode()) {
		out << "NULL";
	     } else {
		out << node.getParentNode()->getId();
	     }

	     out << setw(8) << node.getLabel();
	     out << setw(8) <<
		 (node.isStrong(FALSE) ? "strong" : "weak");
	 }
	 out << endl;
    }
}
@ %def dumpNodes
\subsection{File Boiler Plate}
<<C++ overhead>>=
    PhaseSolver();
<<Solver method implementations>>=
PhaseSolver::PhaseSolver()
{
    <<default Solver constructor>>
}
@
We start with the boiler-plate implementation file. 
<<*>>=
#include "PhaseSolver.h"
#include "debug.h"
#include <iostream.h>
#include <fstream.h>
#include <iomanip.h>
#include <assert.h>
<<implementation header files>>

<<Solver method implementations>>
@
Through magic of the C preprocessor and the macro-like facilities
of {\em noweb}, we can easily define the inline functions
out-of-line to allow us to collect better profile information - 
i.e. collect data on the inline functions that would otherwise
not show up in the function call traces of the profiler.
<<*>>=
#ifndef INLINE_SOLVER
#define INLINE /*inline*/
<<Solver inline implementations>>
#undef INLINE 
#endif /*INLINE_SOLVER*/
@
The header defines the [[Solver]] class, its member functions, member
data, and inline functions.  Again, we have more boiler-plate.
<<header>>=
#ifndef SOLVER_H
#define SOLVER_H
#include "types.h"
#include "Node.h"
<<header include files>>

class PhaseSolver;
typedef void (PhaseSolver::* AddBranchPtr)(Node& root);
typedef void (PhaseSolver::* RenormalizePtr)(Node& strongRoot, Node& weakNode);

<<Node Bucket definition>>

class PhaseSolver 
{
public:
    <<Solver methods>>
    <<C++ overhead>>
    <<public Solver data>>
private:
    <<Solver data>>
};
@ %def Solver
In case we want the inline functions to really be inlined, we
also define them here in the header file.
<<header>>=
#ifdef INLINE_SOLVER
#define INLINE inline
<<Solver inline implementations>>
#undef INLINE 
#endif /*INLINE_SOLVER*/
#endif /*SOLVER_H*/
@
And finally, let's fill out the definition for Node Buckets.
<<Node Bucket definition>>=
class NodeBucket
{
    public: NodeBucket() { head = tail = nil; }
    <<Node Bucket methods>>
    <<Node Bucket data>>
};

<<Node Bucket inline implementations>>

