\section{Phase-based Solver}
The solver manages the entire problem instance.  Initially
this includes the nodes and edges.  These are stored as contiguous
arrays (as opposed to allocating each one with [[new]])
to make memory management fast and simple.  These arrays are allocated
when the problem instance is read.
<<Solver data>>=
    Node*	nodes;
    Edge*	edges;
<<default Solver constructor>>=
    nodes = nil;
    edges = nil;
@ %def nodes edges
Just for safety checking, we should also keep track of the
number of elements in each of these arrays.
<<Solver data>>=
    int		numNodes;
    int		numEdges;
<<default Solver constructor>>=
    numNodes = numEdges = nil;
@ %def numNodes numEdges
We also need to know the source and sink nodes in the graph.
<<Solver data>>=
    NodePtr 	sourceNode;
    NodePtr 	sinkNode;
<<default Solver constructor>>=
    sourceNode = sinkNode = nil;
@ %def sourceNode sinkNode
\subsection{Solving}
At the highest level, solving is pretty simple: we select the
lowest labeled strong branch, process it looking for mergers and 
relabling nodes that do not merge, and continue until we cannot
find a strong branch.
<<Solver methods>>=
    void solve();
<<Solver method implementations>>=
void PhaseSolver::solve()
{
    TRACE(int currentPhase = 0;)
    NodePtr strongBranch = getLowestBranch();
    while (strongBranch != nil) {
	NodeLabel strongLabel =  strongBranch->getLabel();
	TRACE(
	    if ( strongLabel != currentPhase) {
		currentPhase = strongLabel;
		trout << "Phase " << currentPhase << endl;
	    }
	)
	<<terminate early based on counting labels>>
	processBranch(*strongBranch);
	strongBranch = getLowestBranch();
    }
}
@ %def solve
For each possible value for a node's label, if we track the number of 
nodes with each label, then it is possible to terminate the algorithm
early.  If the lowest labeled strong branch has label $\ell$, and
there are no nodes with label $\ell - 1$, then the algorithm is done
because the strong branch cannot merge with any weak branches, and
the labels of the strong branches will only increase further during
execution.
<<terminate early based on counting labels>>=
    #ifdef TERM_LABELS
	if ((labelCount[strongLabel - 1] == 0) && 
	    (strongLabel > INIT_WEAK_LABEL))
	{
	    cout << "Early termination" << endl;
	    break;
	}
    #endif /* TERM_LABELS */
@
\subsection{Processing Branches}
We process the tree one branch at a time looking for mergers or
relabeling nodes.  As soon as there is a merger, we stop processing
this branch to allow the main loop to fetch the next, lowest-labeled
branch from the buckets.  It could be that we resume processing this 
branch, which is OK.  In fact, it is probably desireable since
the branch has been inverted.  If there was no merger, we
move the branch to the next bucket.

As an optimization, we check to see if there are any nodes that
we could possibly merge with before invesigating the branch.
If there are no nodes with a label one less than ours, we just
relabel the whole branch.
<<Solver methods>>=
    void processBranch(Node& root);
<<Solver method implementations>>=
void PhaseSolver::processBranch(Node& root)
{
#ifdef COUNT_LABELS
    if (labelCount[root.getLabel() - 1] == 0) {
#else /* !COUNT_LABELS */
    if (FALSE) {
#endif /* COUNT_LABELS */
	TRACE( trout << "Relabel branch " << root.getId() 
	             << " with label " << root.getLabel() << endl; )
	relabelSubtree(root);
	addStrongBranch(root);	// XXX maybe this should be in solve

    } else {
	Boolean performedMerger = processSubtree(root);
	if (!performedMerger) {
	    addStrongBranch(root);	// XXX maybe this should be in solve
	}
    }
}
@ %def processBranch
Below is recursive code to perform the DFS scan of a node's children and to
look for merger arcs among its neighbors.  Currently, the code
processes the nodes in post-order - i.e. the children are all processed
before the neighbors of this node are scanned.
If this function performs a merger, it returns immediately.
If any part of the sub-tree is split off and strong, it will
be put in the appropriate bucket where [[getLowestBranch]] will
find it.  If there is no merger, the label of this node is incremented.
The function returns true or false if we perform a merger.
<<Solver methods>>=
    Boolean processSubtree(Node& node);
<<Solver method implementations>>=
Boolean PhaseSolver::processSubtree(Node& node)
{
    NodeLabel label = node.getLabel();
    <<process all children>>
    <<look for merger among neighbors>>
    // no merger
    incrementLabel(node);
    node.resetIterations();
    TRACE(trout << "node " << node.getId() << " relabled to "
		<< node.getLabel() << endl;);
    return FALSE;
}
@ %def processSubtree
We process all children that have the same label as ours, [[label]].
If a child has a higher label, we just ignore it.  By monotonicity,
it can't have a label less than ours.  If we process the sub-tree
and that generates a merger we return immediately.
<<process all children>>=
    while (node.hasMoreChildren()) {
	Node& child = node.getCurrentChild();
	assert(child.getLabel() >= label);
	if (child.getLabel() == label) {
	    Boolean performedMerger = processSubtree(child);
	    if (performedMerger) {
		return TRUE;
	    }
	}
	node.advanceChildren();
    }
@
Processing neighbors is a bit different.  Here is where we look for
a merger to a node with label exactly one less that ours
(given that the arc has residual capacity).  
If we find that, we will merge and return true immediately.
<<look for merger among neighbors>>=
    while (node.hasMoreNeighbors()) {
	Edge& neighborEdge = node.getCurrentNeighbor();
	Node& neighbor = *neighborEdge.getOtherNode(&node);
	if ((neighbor.getLabel() == (label - 1)) &&
	    (neighborEdge.residCapacity(node) > 0))
	{
	    merge(node, neighbor, neighborEdge);
	    return TRUE;
	}
	node.advanceNeighbors();
    }
@
This function 
rehangs the strong branch from the strong node, adds the
merger arc from $s$ to $w$, and pushes the excess from the
old strong root to the weak root.  
<<Solver methods>>=
    void merge(Node& strong, Node& weak, Edge& edge);
<<Solver method implementations>>=
void PhaseSolver::merge(Node& strong, Node& weak, Edge& edge)
{
    TRACE( trout << "merge " << strong.getId() << " ("
		   << strong.getRootExcess() << ") to " 
		   << weak.getId() << " ("
		   << weak.getRootExcess() << "), cap "
		   << edge.residCapacity(strong) << endl;)
    Node& strongRoot = *strong.rehang();
    weak.addChild(strong, edge);
    CHECK_TREE(weak, weak.getParentEdge());
    CHECK_TREE(*weak.getRoot(), nil);
    strongPush(strongRoot, weak);
    weakPush(weak);
}
@ %def merge
Push excess from the former strong root, $r_s$ to the strong node, $s$,
and one step beyond to the weak node, $w$.
When this finishes, the remaining excess will be stored on
the destination node.
We save the parent pointer before the push in case there is a
split, in which case the parent pointer will be [[nil]].
<<Solver methods>>=
    void strongPush(Node& src, Node& dest);
<<Solver method implementations>>=
void PhaseSolver::strongPush(Node& src, Node& dest)
{
    NodePtr currNode = &src;
    while (currNode != &dest) {
	NodePtr parent = currNode->getParentNode();
	Boolean performedSplit = currNode->pushToParent();
	<<check for zero-capcity split>>

	if (performedSplit) {
	    if (currNode->getExcess() > 0 ||
	        currNode->getExcess() == 0 && zeroDeficitIsStrong)
	    {	
		addStrongBranch(*currNode);
	    } 
	}
	currNode = parent;
    }
}
@ %def strongPush
We allow special handling if an edge has zero residual capacity.
It could be split or left alone.
<<check for zero-capcity split>>=
    if (performedSplit == FALSE && 
	currNode->getParentCapacity() == 0 &&
	splitOnZeroCapacity) 
    {
	currNode->split();
	performedSplit = TRUE;
    }
@
Pushing on the weak side is similar in that it uses [[pushToParent]]
to push all of the flow, but it differs in that we push all the way
to the root of the branch.
<<Solver methods>>=
    void weakPush(Node& src);
<<Solver method implementations>>=
void PhaseSolver::weakPush(Node& src)
{
    NodePtr currNode = &src;
    NodePtr parent = currNode->getParentNode();

    while (parent != nil) {
	Boolean performedSplit = currNode->pushToParent();
	<<check for zero-capcity split>>

	if (performedSplit) {
	    CHECK_TREE(*currNode, nil);
	    if (currNode->getExcess() > 0 ||
	        currNode->getExcess() == 0 && zeroDeficitIsStrong)
	    {	
		addStrongBranch(*currNode);
	    } 
	}
	currNode = parent;
	parent = currNode->getParentNode();
    }

    CHECK_TREE(*currNode, nil);

    <<check for weak root becoming strong>>
}
@ %def weakPush
After we have pushed flow all the way to the weak root, we need to
check to see if the weak root is now strong.  The weak root is
pointed to by [[currNode]].  One special case we deal with here
is if the weak root has the initial weak label, we know that when 
it goes strong, there will be no one 
for it to merge with (because the weak label is the lowest possible).
Therefore, we can just relabel it here and now before adding it.
<<check for weak root becoming strong>>=
    if (currNode->getExcess() > 0 ||
	currNode->getExcess() == 0 && zeroDeficitIsStrong)
    {
	if (currNode->getLabel() == INIT_WEAK_LABEL) {
	    relabelSubtree(*currNode);
	}
	addStrongBranch(*currNode);
    }
@
In the code above, we used some flags to control some of the
behavior of the code while it's running.  We'll declare this
public so that they can be easily inspected and tweaked.
The first flag controls what happens if we push excess along an
arc that matches the residual capacity.  We could choose to
either split it or leave it alone until the next push sends
flow along the arc, which will cause an immediate split.
<<public Solver data>>=
    Boolean splitOnZeroCapacity;
@
The second flag controls how we regard zero-deficit nodes/branches during
the execution of the algorithm (they are always weak when start the
algorith).  If we treat a zero-deficit node as weak, when the algorithm
finishes, the strong nodes will be a minimal source set.  However, this
can lead to creating weak branch with root nodes whose label is greater
than one.  This in turn makes it very difficult (impossible?) to bound 
the maximum label that weak node can take (if weak roots have label one,
no node can have a label greater than $n$).  If we treat zero-deficit
nodes as strong, weak roots will always have label one, we will never
create any additional zero-deficit nodes/branches, but we have no easy
way to find a minimal source set.
<<public Solver data>>=
    Boolean zeroDeficitIsStrong;
<<default Solver constructor>>=
    splitOnZeroCapacity = FALSE;
    zeroDeficitIsStrong = FALSE;
@ %def splitOnZeroCapacity zeroDeficitIsStrong
Back in [[processSubtree]] we had a simple method call to increment
the label on a node.  Normally, we would just call [[incrementLabel]]
on the node, but we want to track how many nodes we have with each
label so that we can terminate the algorithm early.
<<Solver methods>>=
    void incrementLabel(Node& node);
@
When the label of a node is incremented, we decrement the old label
count by one and increment the new label count.
<<Solver inline implementations>>=
INLINE void PhaseSolver::incrementLabel(Node& node)
{
#ifdef  COUNT_LABELS 
    NodeLabel l = node.getLabel();
    labelCount[l]--;
    labelCount[l + 1]++;
#endif /* COUNT_LABELS */
    node.incrementLabel();
}
@ %def incrementLabel
When we know that a branch cannot merge with
any weak nodes, we need to increment the label
of the branch, and all of its children that have the same label.
This is really a stripped down version of [[processSubtree]].
Given the early termination code based on counting nodes and labels,
this code isn't usually needed.  It might be useful for some
tree initialization schemes that result in strong branches with
the initial weak label.
<<Solver methods>>=
    void relabelSubtree(Node& node);
<<Solver method implementations>>=
void PhaseSolver::relabelSubtree(Node& node)
{
    NodeLabel label = node.getLabel();
    node.resetIterations();
    while (node.hasMoreChildren()) {
	Node& child = node.getCurrentChild();
	assert(child.getLabel() >= label);
	if (child.getLabel() == label) {
	    relabelSubtree(child);
	}
	node.advanceChildren();
    }

    incrementLabel(node);
    node.resetIterations();
    TRACE(trout << "node " << node.getId() << " Relabled to "
		<< node.getLabel() << endl;);
}
@ %def processSubtree
\subsection{Delayed Normailization}
Delayed normalization will require a different merge function
and a different solve function that knows to renormalize if it
detects a termination condition.
We will have a pointer to member function on the solver to
select the proper merge function.  This will allow us to
reuse [[processSubTree]].  The new merge function will just
not perform weakPush, or maybe it will just push it one step.

The renormalize function will scan all nodes looking for positive
excess and parents. If so, we must have a weak node so we can just
call weakPush.  We might want to push only one level up, but that 
might be too much work.
\subsection{Managing Strong Branches}
We manage strong branches using an array of linked lists of Nodes.
We refer to each such element in the array as a `bucket'.
The buckets are indexed by the labels of the nodes.  Therefore,
we need a bucket for each possible label - basically $n$ buckets.
For each bucket, we keep the head and tail of the list so that
we can manage them as either FIFO or LIFO.
<<Solver data>>=
    NodePtr*	bucketHeads;
#ifdef LIFO_BUCKETS
    NodePtr*	bucketTails;
#endif /* LIFO_BUCKETS */
<<default Solver constructor>>=
    bucketHeads = nil;
#ifdef LIFO_BUCKETS
    bucketTails = nil;
#endif /* LIFO_BUCKETS */
@ %def bucketHeads bucketTails
Because we process the lowest labeled branch, we need a way to find
the strong branch quickly.  At the moment, we just search the list
sequentially looking for the lowest labeled, non-empty bucket.  To
speed this a bit, we keep track of the lowest labeled bucket we've
seen.  In the future, this simple array of buckets could be replaced
by some sort of heap.
<<Solver data>>=
    NodeLabel 	lowestLabel;
<<default Solver constructor>>=
    lowestLabel = 0;
@ %def lowestLabel
Adding a branch just requires finding the bucket based on the branch's
label, and inserting it into the list.  
<<Solver methods>>=
    void addStrongBranch(Node& root);
<<Solver method implementations>>=
void PhaseSolver::addStrongBranch(Node& root)
{
    NodeLabel label = root.getLabel();
    assert(zeroDeficitIsStrong ? (root.getExcess() >= 0) :
				 (root.getExcess() > 0));
    CHECK_TREE(root, nil);
    // put in correct bucket
    if (bucketHeads[label] == nil) {
	root.setNextNil();
	bucketHeads[label] = &root;
#ifdef LIFO_BUCKETS
	bucketTails[label] = &root;
#endif /* LIFO_BUCKETS */
    } else {
#ifdef LIFO_BUCKETS
	if (lastRoot != &root) {
	    bucketTails[label]->setNext(&root);
	    bucketTails[label] = &root;
	    root.setNextNil();
	} else {
	    // it's the same root we deal with before - put it at the head
	    root.setNext(bucketHeads[label]);
	    bucketHeads[label] = &root;
	}
#else /* !LIFO_BUCKETS -i.e. FIFO */
	root.setNext(bucketHeads[label]);
	bucketHeads[label] = &root;
#endif /* LIFO_BUCKETS */
    }
    // look for new, lower label
    if (label < lowestLabel) {
	lowestLabel = label;
    }
}
<<Solver data>>=
    NodePtr lastRoot;
<<default Solver constructor>>=
    lastRoot = nil;
@ %def addStrongBranch
As the algorithm runs, we need to remove the lowest labeled branch.
First we need to locate the lowest labeled bucket, then we need to
remove the head of the list.  If there are no more strong branches,
we just return [[nil]].

The search always starts at the [[lowestLabel]] bucket.  As we
scan buckets, we increment [[lowestLabel]] until we find a 
non-empty bucket.
{\em What exactly should the termination condition be?}
<<Solver methods>>=
    NodePtr getLowestBranch();
<<Solver method implementations>>=
NodePtr PhaseSolver::getLowestBranch()
{
    NodePtr result = nil;
    while (lowestLabel < numNodes) {
	if (bucketHeads[lowestLabel] != nil) {
	    result = bucketHeads[lowestLabel];
	    bucketHeads[lowestLabel] = result->getNext();
#ifdef LIFO_BUCKETS
	    if (bucketHeads[lowestLabel] == nil) {
		bucketTails[lowestLabel] = nil;
	    }
#endif /* LIFO_BUCKETS */
	    result->setNextNil();
	    break;
	} else {
	    lowestLabel++;
	}
    }

    lastRoot = result;
    return result;
}
@ %def getLowestBranch
\subsection{Establishing an Initial Normalized Tree}
There are a number of different ways that we can build an initial,
normalized tree.  Building the initial tree is totally independent
of the execution of the algorithm.  

\subsubsection{Simple Initialization}
At the very least, this simplest initialization
needs to saturate all source- and sink.adjacent edges and
source-adjacent nodes 2, and label the others 1.
classify the nodes as strong or weak.
<<Solver methods>>=
    void buildSimpleTree();
<<Solver method implementations>>=
void PhaseSolver::buildSimpleTree()
{
    saturateSourceSinkArcs();
    setInitialNodeStatus();
}
@ %def buildSimpleTree
The code to saturate the source- and sink-adjacent arcs is
broken out into a separate function because many schemes
for building the initial tree will want start by saturating
these arcs.  When we saturate an edge, we remove it from the list
of arcs for the node.  This will prevent flow from going back to
either the source or the sink without having to special-case these
arcs at run-time.
<<Solver methods>>=
    void saturateSourceSinkArcs();
<<Solver method implementations>>=
void PhaseSolver::saturateSourceSinkArcs()
{
    for (int i = 0 ; i < numEdges; i++) {
	Edge& edge = edges[i];
	if (edge.getTail() == sourceNode) {
	    FlowAmount excess = edge.saturate();
	    Node& srcAdjNode = *edge.getHead();
	    srcAdjNode.removeNeighbor(edge);
	    srcAdjNode.incrementExcess(excess);
	} else if (edge.getHead() == sinkNode) {
	    FlowAmount excess = edge.saturate();
	    Node& sinkAdjNode = *edge.getTail();
	    sinkAdjNode.decrementExcess(excess);
	    sinkAdjNode.removeNeighbor(edge);
	}
    }
}
@ %def saturateSourceSinkArcs
Again, since determining the initial status of nodes is apt
to be a common subroutine of many initialization procedures,
we have it as a separate method.  We simply iterate over
all of the nodes setting their initial labels based on their
excess.  Anything with positive excess is assumed to be
strong, and everything else is assumed to be weak.
Strong nodes are added as strong branches.

{\em Note:} this code assumes that each node is it's own
branch - i.e. no trees or paths have been built up.  
If we have built any branches, then the non-root nodes will
have zero excess, but we cannot immediately discern their
status based simply on their excess.  In order to make this
method useful to schemes that may build up branches, we
check the label of the branch.  If it is still at the initial value
from when the node was created, we assume it is safe for us to
label it.
<<Solver methods>>=
    void setInitialNodeStatus();
<<Solver method implementations>>=
void PhaseSolver::setInitialNodeStatus()
{
    for (int i = 1; i <= numNodes; i++) {
	Node& node = nodes[i];
	if (node.getLabel() == Node::INITIAL_LABEL) {
	    if (node.getExcess() > 0) {	// ZERO DEFICIT
		node.setLabel(INIT_STRONG_LABEL);
		labelCount[INIT_STRONG_LABEL]++;
		addStrongBranch(node);
	    } else {
		node.setLabel(INIT_WEAK_LABEL);
		labelCount[INIT_WEAK_LABEL]++;
	    }
	}
    }
}
@ %def setInitialNodeStatus
<<Solver data>>=
    int* labelCount;
<<default Solver constructor>>=
    labelCount = nil;
@ %def labelCount 
<<Solver data>>=
    static const int INIT_STRONG_LABEL=2;
    static const int INIT_WEAK_LABEL=1;
    static const int INIT_ZERO_LABEL=1;
@ %def INIT_STRONG_LABEL INIT_WEAK_LABEL INIT_ZERO_LABEL
\subsubsection{Blocking Path Initialization}
A simple extension to the idea of just simply saturating the
source- and sink-adjacent arcs is to try to push flow from the
source-adjacent nodes into the interior of the graph.  Our
objective is to try to build some simple but large components
with a minimum of work.

This is a bit more involved than it initially appeared.
The first thing to note is that the components we will build will
be paths.  This means that we can only push flow out of a node
along a single outgoing arc.  Also, we can only push flow into
a node from a single neighbor.  Otherwise, we might end up building
components that are not trees.

Because we wish to build components that are as large as possible
(rather than creating lots of small components), we want to avoid
splitting edges.  However, this can be problematic because many of
the random graphs we test with have more in-capacity than out-capacity
for the source-adjacent nodes.  If we blindly avoid splitting, we
won't move any flow from the source-adjacent nodes because they
have more excess than out-capacity.  

One final complication is that if we sucessfully push flow into a
node and then out of it, then its excess will be zero, but the node
should be regarded as strong because it belongs to a strong branch
(path).

With all of this in mind, we proceed by finding nodes with 
positive excess that still have their initial label.
We then push the flow out of the node and expect that every node
we visit while pushing flow will be relabeled.  Basically, we
are using the node's label as a marker indicating that we have
visited the node.

<<Solver methods>>=
    void buildGreedyPushTree();
<<Solver method implementations>>=
void PhaseSolver::buildGreedyPushTree()
{
    saturateSourceSinkArcs();

    for (int i = 1; i <= numNodes; i++) {
	Node& node = nodes[i];
	if ((node.getExcess() > 0) && 
	    (node.getLabel() == Node::INITIAL_LABEL))
	{	
	    pushFlowOut(node);
	}
    }

    setInitialNodeStatus();
}
@ %def buildGreedyPushTree
The real work in this greedy scheme is pushing the flow out of a
node.  This recursive function finds the `best' edge to push the
flow out on, and then we push the flow.  When we push flow out,
we make this node a child of the node at the other end of the arc,
and then we try to push flow out of that node (hence the recursion).
As we visit each node, we relabel it to prevent visiting the same node
more than once.

The function returns true if we eventually push the excess to
a sink-adjacent node with negative execess that exceeds the 
amount we are pushing.  In this case, we have created a weak
branch.  If we reach a point where the flow cannot be pushed
out of a node, that node then becomes the root of a strong branch,
and the function returns false.
<<Solver methods>>=
    Boolean pushFlowOut(Node& node);
<<Solver method implementations>>=
Boolean PhaseSolver::pushFlowOut(Node& node)
{
    Boolean foundSink = FALSE;
    node.setLabel(INIT_STRONG_LABEL);
    labelCount[INIT_STRONG_LABEL]++;

    NodeExcess excess = node.getExcess();
    Edge* bestOutEdge = nil;
    <<find best out edge>>

    FlowAmount flow = excess;
    if (bestOutEdge != nil) {
	Node& otherNode = *bestOutEdge->getOtherNode(&node);
	TRACE( trout << "push positive excess (" << flow << " from " 
		     << node.getId() << " to " << otherNode.getId() << endl);
	         
	bestOutEdge->increaseFlow(flow);
	node.decrementExcess(flow);
	otherNode.incrementExcess(flow);
	otherNode.addChild(node, *bestOutEdge);

	<<recursively push flow out>>
    } else {
	TRACE( trout << "can't push excess from " << node.getId() << endl; )
	addStrongBranch(node);
    }

    return foundSink;
}
@ %def pushFlowOut
To find the best out edge, we iterate over all of the edges looking
for one that has at least enough capacity to handle the excess.  Also,
the edge must refer to a node that we haven't visited yet, as indicated
by its label.  If we find multiple edges with sufficient capacity, we
take the one with the least capacity.  Alternatively, we could take
the first fit, but we do not expect that scanning every edge will be
too burdensome.
<<find best out edge>>=
    node.resetIterations();
    while (node.hasMoreNeighbors()) {
	Edge& edge = node.getCurrentNeighbor();
	if (edge.getOtherNode(&node)->getLabel() == Node::INITIAL_LABEL) {
	    if (edge.residCapacity(node) >= excess) {
		if (bestOutEdge == nil) {
		    bestOutEdge = &edge;
		} else if (bestOutEdge->residCapacity(node) > edge.residCapacity(node)) {
		    bestOutEdge = &edge;
		}
	    }
	    // else, could also track max capacity edge to split here
	}
	node.advanceNeighbors();
    }
    node.resetIterations();
@
One would think that continuing to push flow out would be pretty simple:
just call [[pushFlowOut(otherNode)]].  However, it's not that easy.
If we get lucky, we have pushed flow all the way to a sink-adjacent
node.  If that node had a negative excess that exceeds the excess
we are pushing out of [[node]], then we have have created a weak
branch, but we have already labeled all of the nodes as strong.  As
a slightly cheezy hack, we will undo the labeling.  Another solution
would be a more sophisticated version of [[setInitialNodeStatus]] that
finds roots of branches and labels all children strong or weak depending
on the root.
<<recursively push flow out>>=
    if (otherNode.getExcess() > 0) {	// ZERO_DEFICIT
	foundSink = pushFlowOut(otherNode);
    } else {
	TRACE( trout << "found sink-adjacent node " << otherNode.getId() << endl;)
	foundSink = TRUE;
	CHECK_TREE(otherNode, nil);
    }

    if (foundSink) {
	TRACE( trout << "relabeling "  << node.getId() << " as weak " << endl;)
	labelCount[INIT_STRONG_LABEL]--;
	node.setLabel(INIT_WEAK_LABEL);
	labelCount[INIT_WEAK_LABEL]++;
    }
@
\subsubsection{Splitting Path Initialization}
\subsubsection{Staturate All Arcs}
\subsection{Input Output Functions}
We need routines to read Dimacs problem files and write 
Dimacs flow files.  At the moment, these are member
functions on the solver.  An alternative design would
be to put them in a separate class or file to allow us
to support multiple input file formats for the same 
solver class.

Our function to read a problem instance is given a file name and
return true if it sucessfully read the problem instance from the
specified file.
<<Solver methods>>=
    Boolean readDimacsInstance(const char* filename);
@
Our code will be divided into two steps. In the first
steps we will determine the basic dimensions of the problem, initialize
the edges, and compute the degree of each node.  Once we know the degree
of the nodes, we can initialize them and add all of their neighbors.

The code below uses C standard I/O ([[stdio]]) because I'm too lazy
to figure out how to use C++ I/O streams.  
<<Solver method implementations>>=
Boolean PhaseSolver::readDimacsInstance(const char* filename)
{
    FILE* fp = fopen(filename, "r");
    if (fp != NULL) {
	instanceFilename = filename;
	<<local variables for reading>>
	<<read instance and initialize edges>>
	<<initialize nodes>>
    } else {
	perror("Unable to read problem instance");
	return FALSE;
    }
    return TRUE;
}
<<implementation header files>>=
#include <stdio.h>
<<Solver data>>=
    const char* instanceFilename;
<<default Solver constructor>>=
    instanceFilename = "<unknown instance>";
@ %def readDimacsInstance
Reading the problem instance is farily straightforward.  We
read lines until the end of file.  Each line
in the file is identified by a `type character' that specifies what
type of line we are reading.  The type then determines how much more
information is on the line.  The additional information will begin 
at the third character in the line.
<<read instance and initialize edges>>=
    while (!feof(fp)) {
	char buffer[500];
	if (fgets(buffer, 500, fp) == NULL) {
	    break;
	}
	char* moreInfo = &buffer[2];
	char type;
	sscanf(buffer, "%c", &type);
	<<parse line>>
    }
@ 
Parsing the type code is a pretty simple switch statment.
<<parse line>>=
    switch (type) {
	case 'c':	// comment
	    break;
	case 'p':	// problem dimensions
	    <<allocate problem instance>>
	    break;
	case 'n':   {	// specify source or sink
	    <<specify source/sink>>
	    break;
	}
	case 'a':	// read an edge
	    <<read edge>>
	    break;
	default:
	    cerr << "Unrecognized input line: " << buffer << endl;
	    break;
    }
@
The problem instance has a problem type string, number of nodes,
and number of instances.  In addition to allocating the array
of nodes, we also allocate and zero an array of integers that we
will use to count the degree of each node as we read each edge.
Note that node id's begin at one rather than zero, so we need to
allocate an extra node (node zero), that never really gets used.
<<allocate problem instance>>=
    char typeBuffer[20];
    numTokens = sscanf(moreInfo, "%s %d %d", typeBuffer, &numNodes, &numEdges);
    if ((numTokens != 3) || (numNodes <= 0) || (numEdges <= 0)) {
	cerr << "Invalid problem instance line: " << buffer << endl;
	return FALSE;
    }
    nodes = new Node[numNodes + 1];
    edges = new Edge[numEdges];
    bucketHeads = new NodePtr[numNodes + 1];
#ifdef LIFO_BUCKETS
    bucketTails = new NodePtr[numNodes + 1];
#endif /* LIFO_BUCKETS */
    nodeDegrees = new int[numNodes + 1];
    labelCount = new int[numNodes + 1];

    for (int i = 0; i <= numNodes; i++) {
	nodeDegrees[i] = labelCount[i] = 0;
	bucketHeads[i] = nil;
#ifdef LIFO_BUCKETS
	bucketTails[i] = nil;
#endif /* LIFO_BUCKETS */
    }
<<local variables for reading>>=
    int numTokens = 0;
    int* nodeDegrees = nil;
@ 
The source and sink in the graph are simply specified by a node number and `s'
for the source and `t' for the sink.
<<specify source/sink>>=
    char sourceSinkFlag;
    int nodeNumber;
    numTokens =  sscanf(moreInfo, "%d %c", &nodeNumber, &sourceSinkFlag);
    if ((numTokens != 2) || (nodeNumber <= 0) || (nodeNumber > numNodes)) {
	cerr << "Invalid source/sink line: " << buffer << endl;
	return FALSE;
    }

    if (sourceSinkFlag == 's') {
	sourceNode = &nodes[nodeNumber];
    } else if (sourceSinkFlag == 't') {
	sinkNode = &nodes[nodeNumber];
    } else {
	cerr << "Invalid source/sink line: " << buffer << endl;
	return FALSE;
    }
@ 
An edge is specified by a source, destination and a capacity.
<<read edge>>=
    int source, dest, capacity;
    numTokens =  sscanf(moreInfo, "%d %d %d", &source, &dest, &capacity);
    if ((numTokens != 3) || (source <= 0) || (source > numNodes) ||
	(capacity < 0)   || (dest <= 0)   || (dest > numNodes)) {
	cerr << "Invalid edge line: " << buffer << endl;
	return FALSE;
    }

    if (nextEdge < numEdges) {
	edges[nextEdge].init(nodes[source], nodes[dest], capacity);
	nextEdge++;
	nodeDegrees[source]++;
	nodeDegrees[dest]++;
    } else {
	cerr << "Too many edges - graph should only contain " << numEdges << endl;
	return FALSE;
    }
<<local variables for reading>>=
    int nextEdge = 0;
@
To initialize the nodes, we call their [[init]] method to allocate
space for neighbors based on the degree of each node that we observered
while reading edges.  We can trivially assign each node it's id number.
<<initialize nodes>>=
    for (int i = 1; i <= numNodes; i++) {
	nodes[i].init(i, nodeDegrees[i]);
    }
@
Once the nodes are initialized, we can easily iterate over the list of 
edges and add each endpoint to the other's list of neighbors.  Note,
we only scan the edges that we actually read (based on [[nextEdge]])
rather than the number we could have seen (specified by [[numEdges]]).
<<initialize nodes>>=
    for (int i = 0; i < nextEdge; i++) {
	edges[i].getHead()->addNeighbor(edges[i]);
	edges[i].getTail()->addNeighbor(edges[i]);
    }
@
Finally, let's remember to free up the memory we allocated to count
node degrees.
<<initialize nodes>>=
    delete[] nodeDegrees;
@
After we read an instance and solve it, we need to write the result
out.  The Dimacs flow file is very similar to the instance in
that every line is identified by an initial type character followed
by arguments.  After printing header information, we print the
total flow amount and the flow on each arc.
<<Solver methods>>=
    void writeDimacsFlow(ostream& dout);
<<Solver method implementations>>=
void PhaseSolver::writeDimacsFlow(ostream& dout)
{
    <<write header>>
    dout << "s " << 0 << endl;
    <<dump arcs>>
}
@ %def writeDimacsFlow
<<write header>>=
    // dout << "c  instance: " << instanceFilename << endl;
    dout << "c  numNodes: " << numNodes << endl;
    dout << "c  numArcs: "  << numEdges << endl;
    dout << "c" << endl;
@
To dump the edges, we just iterate over the array of edges and 
print them out.
<<dump arcs>>=
    for (int i = 0; i < numEdges; i++) {
	edges[i].writeFlow(dout) << endl;
    }
@
Here is a new method to print the final disposition of all of the nodes
in the graph.  
<<Solver methods>>=
    void dumpNodes(ostream& out);
<<header include files>>=
    class ostream;
<<Solver method implementations>>=
void PhaseSolver::dumpNodes(ostream& out)
{
    out << "c" << endl
        << "c Node  id   excess  parent strong/weak" << endl;

    for (int i = 1; i <= numNodes; i++) {
	Node& node = nodes[i];
	out << "c " << setw(8) << node.getId() << " " << setw(8);
	if (&node == sourceNode) {
	    out << "source";
	} else if (&node == sinkNode) {
	    out << "sink";
	} else {
	     out << node.getExcess() << setw(8);
	     if (node.isRootNode()) {
		out << "NULL";
	     } else {
		out << node.getParentNode()->getId();
	     }

	     out << setw(8) <<
		 (node.isStrong(FALSE) ? "strong" : "weak");
	 }
	 out << endl;
    }
}
@ %def dumpNodes
\subsection{File Boiler Plate}
<<C++ overhead>>=
    PhaseSolver();
<<Solver method implementations>>=
PhaseSolver::PhaseSolver()
{
    <<default Solver constructor>>
}
@
We start with the boiler-plate implementation file. 
<<*>>=
#include "PhaseSolver.h"
#include "debug.h"
#include <iostream.h>
#include <fstream.h>
#include <iomanip.h>
#include <assert.h>
<<implementation header files>>

<<Solver method implementations>>
@
Through magic of the C preprocessor and the macro-like facilities
of {\em noweb}, we can easily define the inline functions
out-of-line to allow us to collect better profile information - 
i.e. collect data on the inline functions that would otherwise
not show up in the function call traces of the profiler.
<<*>>=
#ifndef INLINE_SOLVER
#define INLINE /*inline*/
<<Solver inline implementations>>
#undef INLINE 
#endif /*INLINE_SOLVER*/
@
The header defines the [[Solver]] class, its member functions, member
data, and inline functions.  Again, we have more boiler-plate.
<<header>>=
#ifndef SOLVER_H
#define SOLVER_H
#include "types.h"
#include "Node.h"
<<header include files>>

class PhaseSolver 
{
public:
    <<Solver methods>>
    <<C++ overhead>>
    <<public Solver data>>
private:
    <<Solver data>>
};
@ %def Solver
In case we want the inline functions to really be inlined, we
also define them here in the header file.
<<header>>=
#ifdef INLINE_SOLVER
#define INLINE inline
<<Solver inline implementations>>
#undef INLINE 
#endif /*INLINE_SOLVER*/

#endif /*SOLVER_H*/
